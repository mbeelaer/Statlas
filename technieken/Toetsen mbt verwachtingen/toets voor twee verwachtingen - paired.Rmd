---
title: "Toets voor twee verwachtingen - afhankelijke steekproeven"
output:
  html_document: 
    number_sections: true
    toc: true
    toc_depth: 1
    toc_float: true
    css: C:\Users\michi\Documents\FPPW. Project statistische technieken\pagina's\statlas_technieken.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment='', 
                      prompt=FALSE, 
                      class.source="r-chunk", 
                      class.output="chunk-output")
```

<!--  {-} of {.unnumbered} na header zorgt ervoor dat deze sectie niet wordt genummerd ondanks "number_sections: TRUE" in YAML -->

<br>

------------------------

Op deze pagina wordt een statistische techniek gedemonstreerd aan de hand van een voorbeeld. Meer informatie over hoe je deze pagina kan gebruiken vind je in deze <a href="https://statlas.ugent.be/andere paginas/handleiding.html" target="_blank">handleiding</a>. 

De analyse gebeurt met behulp van R en RStudio. Een inleiding tot deze software vind je <a href="https://ufora.ugent.be/d2l/le/discovery/view/course/386505" target="_blank">hier</a>.

------------------

# Doel

Met deze toets kan je nagaan of er een verschil is tussen twee groepen waarbij de individuele metingen in beide groepen rechtstreeks gelinkt zijn aan elkaar, bijvoorbeeld metingen bij een persoon voor en na een behandeling.


## Beter alternatief? {-}

De toets die in dit voorbeeld wordt gedemonstreerd is een statistische techniek die tegenwoordig minder vaak wordt gebruikt.

De reden hiervoor is dat er een beter alternatief is: met een repeated measures analyse kan je indien gewenst meerdere predictoren en meer dan twee metingen analyseren.

-------------

```{r, echo=FALSE}

mijn_data <- read.csv("https://statlas.ugent.be/datasets/interesse.csv") 

```


# Voorbeeld
In een poging om de interesse voor het vak geschiedenis op te krikken, laat je leerlingen uit het secundair onderwijs een hele les op zoek gaan naar informatie over een zelfgekozen onderwerp. Je verwacht dat deze vorm van zelfgestuurd leren de interesse voor het vak zal verhogen. 

Je verzamelt gegevens om je vermoeden te onderzoeken. Je trekt een steekproef van leerlingen en je bevraagt hen voor en na de les.

<br>

-------------------

# Data importeren

De data bij dit voorbeeld kan je met het onderstaande commando importeren in R.

```{r, eval=FALSE}

mijn_data <- read.csv("https://statlas.ugent.be/datasets/interesse.csv")

```

<br>

Inspecteer de data met de functie `str()`.

```{r}

str(mijn_data)

```

<br>

----------------------

# Hypothesen

De hypothesen die bij deze toets horen zijn:

<p style="text-align: center;">$H_0: \mu_{na} = \mu_{voor}$ of $\mu_{na}-\mu_{voor} = 0$</p>  
<p align="center">$H_a: \mu_{na} > \mu_{voor}$ of $\mu_{na}-\mu_{voor} > 0$</p>

<br>

De alternatieve hypothese $H_a$ is hier eenzijdig. Meer uitleg over eenzijdig versus tweezijdig toetsen vind je <a href="https://statlas.ugent.be/cursussen/Statistiek I syllabus 20-21.pdf#page=238" target="_blank">hier</a>.

<br>

---------------------------------

# Data verkennen

In dit voorbeeld wil je de interesse voor de les vergelijken met de interesse na de les. Met de functie `summary()` krijg je een eerste indruk van de variabelen in de dataset. Je ziet dat het gemiddelde (`Mean`) van de interesse na de les iets hoger ligt dan ervoor. Verderop zullen we ons de vraag stellen of dit verschil aan toeval kan liggen.

```{r}

summary(mijn_data)

```

<br>

Een eerste, visuele indruk van de gegevens kan je verkrijgen door twee boxplots te maken: één voor de meting voor de les en één voor de meting na de les. Met de code hieronder zorg je ervoor dat de beide boxplots in één figuur worden getoond.


```{r}

boxplot(mijn_data$score.voor, mijn_data$score.na, # Twee vectoren met data, dus er worden twee boxplots gemaakt
        main="Boxplots van interesse voor en na de les",
        names=colnames(mijn_data)[3:4],  
        xlab="Moment van meting", 
        ylab="Interesse in het vak geschiedenis"
        )

```

<br>

------------------------

# Keuze toets 
We vergelijken de verwachtingen in twee groepen. De steekproeven zijn afhankelijk: er is een directe link tussen een meting uit de ene groep en een meting uit de andere groep. De metingen worden namelijk bij dezelfde leerling uitgevoerd.

Deze toets kunnen we uitvoeren met behulp van de functie `t.test()`. 

## Assumpties {-}
* De variabele moet tenminste van intervalniveau zijn. Dat is het geval in dit voorbeeld.

* Daarnaast: 
    + ofwel moet de steekproef voldoende groot zijn (de vuistregel is $n \geq 30$). 
    
        ```{r}
        
        dim(mijn_data)[1] # Met deze code vraag je hoeveel rijen er zijn in de dataset
        
        ```
    
        Er zijn slechts `r dim(mijn_data)[1]` observaties (leerlingen), dus de steekproef is niet groot genoeg.
        
    + ofwel moet het verschil tussen de beide metingen normaal verdeeld zijn. Dit kan je nagaan door een nieuwe vector aan te maken, die berekend wordt als het verschil `score.na - score.voor`. Van die nieuwe vector `d` vraag je vervolgens een QQ-plot op. Hier zie je wel enkele afwijkingen, maar slechts bij een kleine minderheid van datapunten. Je kan de toets uitvoeren, maar je zal misschien voorzichtig moeten zijn bij het maken van een conclusie.

        ```{r}
        
        d <- mijn_data$score.na - mijn_data$score.voor
        qqnorm(d)
        qqline(d)
        
        ```
    
<br>
  
----------------------

# Significantieniveau

Voor je de toets uitvoert, moet je een significantieniveau $\alpha$ kiezen.

```{r}

alpha <- 0.05

```

<br>

----------------------

# Toets

Met onderstaande code kan je de toets uitvoeren. Let op het argument `paired=TRUE`. Dit is nodig omdat het om afhankelijke steekproeven gaat. 

```{r}

t.test(x=mijn_data$score.na, y=mijn_data$score.voor, alternative="greater", conf.level=1-alpha, paired=TRUE)

```

<br>

----------------

```{r, echo=FALSE}

toets <- t.test(x=mijn_data$score.na, y=mijn_data$score.voor, alternative="greater", conf.level=1-alpha, paired=TRUE)
p.waarde <- toets$p.value
bi <- toets$conf.int
```

# Conclusie 

Je stelt vast dat de p-waarde $`r p.waarde` < `r alpha`$. De data bevatten dus voldoende sterk bewijs tegen de nulhypothese. Je verwerpt bijgevolg de nulhypothese op het $`r (1-alpha)*100`\%$ significantieniveau.

Merk op dat de p-waarde hier duidelijk kleiner is dan het significantieniveau $\alpha$. Het is geen randgeval en daardoor kan je vrij veel vertrouwen hebben in de juistheid van je conclusie, ook al was niet perfect voldaan aan de assumpties (zie eerder).

Je kan tot dezelfde conclusie komen aan de hand van het betrouwbaarheidsinterval. Je stelt vast dat de waarde $0$ zich niet in het $`r (1-alpha)*100`\%$ betrouwbaarheidsinterval $[`r bi[1]`, `r bi[2]`[$ bevindt. De nulhypothese, die stelt dat er geen verschil is tussen beide groepen, is dus niet compatibel met de geobserveerde data. Je verwerpt bijgevolg de nulhypothese op het $`r alpha*100`\%$ significantieniveau.